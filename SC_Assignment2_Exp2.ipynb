{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC_Assignment2_Exp2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZKG2zGZtTO3kqfZfaWV+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahriar-Tonmoy/Bangla_writtendigit_recognization/blob/master/SC_Assignment2_Exp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11Hyzg53Gxmk"
      },
      "source": [
        "!pip install gdown\n",
        "!gdown --id '1-0Mc5nKDRGPEi5FBTA0hGLS6OgvTgDMq'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCFggSp4HLnv"
      },
      "source": [
        "!rm './SC_Dataset_Assignment2.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65O3wE_fHNni"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import time,sys\n",
        "import copy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pathlib\n",
        "import zipfile\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import torch.optim as optim\n",
        "import pathlib\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "!pip install torchviz\n",
        "from torchviz import make_dot, make_dot_from_trace\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qukUWyYUHQBs"
      },
      "source": [
        "base_dir ='./SC_Dataset_Assignment2' \n",
        "BATCH_SIZE = 32\n",
        "\n",
        "IMAGE_SIZE = 28\n",
        "LEARNING_RATE = 0.01\n",
        "TEST_SIZE = 0.2\n",
        "OUTPUT_DIM=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL_h6cKHHUBL"
      },
      "source": [
        "# transform = transforms.Compose([\n",
        "\n",
        "#                                 transforms.Grayscale(),  \n",
        "#                                 transforms.Resize(IMAGE_SIZE),  \n",
        "#                                 transforms.CenterCrop(IMAGE_SIZE), \n",
        "#                                 transforms.ToTensor(),\n",
        "#                                ])\n",
        "\n",
        " \n",
        "# dataset = torchvision.datasets.ImageFolder(base_dir, transform=transform)\n",
        "# n = len(dataset) \n",
        "# n_test = int(TEST_SIZE * n) \n",
        "# trainDataset, validDataSet = torch.utils.data.random_split(dataset,[n - n_test,n_test])\n",
        "# trainloader = torch.utils.data.DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True,) \n",
        "# validationloader = torch.utils.data.DataLoader(validDataSet, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True,) \n",
        "# print(\"Length of the trainloader:\", len(trainloader ) * BATCH_SIZE)\n",
        "# print(\"Length of the validationloader:\", len(validationloader ) * BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1EfW6A0Oojp"
      },
      "source": [
        "trainDataset = torchvision.datasets.FashionMNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n",
        "                            download=True)\n",
        "\n",
        "validDataSet = torchvision.datasets.FashionMNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(dataset=trainDataset, \n",
        "                                           batch_size=BATCH_SIZE, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "validationloader = torch.utils.data.DataLoader(dataset=validDataSet, \n",
        "                                          batch_size=BATCH_SIZE, \n",
        "                                          shuffle=False)  \n",
        "\n",
        "print(\"Length of the trainloader:\", len(trainloader ) * BATCH_SIZE)\n",
        "print(\"Length of the validationloader:\", len(validationloader ) * BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdn7lqdXHWj9"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNAndrslHfVz"
      },
      "source": [
        "class LIN_MODEL_3(torch.nn.Module): \n",
        "    def __init__(self,outDim):\n",
        "        super(LIN_MODEL_3, self).__init__()\n",
        "\n",
        "        self.fc_1 = torch.nn.Linear(784, 512)\n",
        "        self.fc_2 = torch.nn.Linear(512, 256)\n",
        "        self.fc_3 = torch.nn.Linear(256,128)\n",
        "        self.fc_4 = torch.nn.Linear(128,64)\n",
        "        self.fc_6 = torch.nn.Linear(64, outDim)\n",
        " \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, 28 * 28) \n",
        "        x = torch.nn.functional.relu(self.fc_1(x))\n",
        "        x = torch.nn.functional.relu(self.fc_2(x))\n",
        "        x = torch.nn.functional.relu(self.fc_3(x))\n",
        "        x = torch.nn.functional.relu(self.fc_4(x))\n",
        "        x = torch.nn.functional.relu(self.fc_6(x))\n",
        "\n",
        "        return x\n",
        "        \n",
        "model_2 = LIN_MODEL_3(OUTPUT_DIM).to(device)\n",
        "\n",
        "summary( model_2, input_size=(1, 28, 28))\n",
        "print(model_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHkXRjxVHkQU"
      },
      "source": [
        "def save_model(\n",
        "               MODEL_USED,\n",
        "               SAVEPATH,\n",
        "               epoch, \n",
        "               batch_size, \n",
        "               model,\n",
        "               optimizer,\n",
        "               image_size,\n",
        "               tranning_loss=[],\n",
        "               tranning_acc=[],\n",
        "               validation_loss=[],\n",
        "               validation_acc=[],\n",
        "               learning_rate=0.001,\n",
        "               meta_data=None):\n",
        "  SAVEPATH += f\"{MODEL_USED}-checkpoint-epoch-{epoch}.pt\"\n",
        "  save_obj = {\n",
        "       'MODEL_USED':MODEL_USED,\n",
        "       'batch_size':batch_size,\n",
        "       'epoch': epoch,\n",
        "       'model_full': model,\n",
        "       'optimizer_full': optimizer,\n",
        "       'model_state': model.state_dict(),\n",
        "       'optimizer_state': optimizer.state_dict(),\n",
        "       'image_size': image_size,\n",
        "       'tranning_loss': tranning_loss,\n",
        "       'tranning_acc': tranning_acc,\n",
        "       'validation_loss': validation_loss,\n",
        "       'validation_acc': validation_acc,\n",
        "       'learning_rate':learning_rate,\n",
        "       'meta_data':meta_data\n",
        "       }\n",
        "\n",
        "  torch.save(save_obj, SAVEPATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFZNEqPIHod5"
      },
      "source": [
        "def train_model(start, end, \n",
        "                model_used ,\n",
        "                model_save_path, \n",
        "                model, \n",
        "                criterion, \n",
        "                optimizer, \n",
        "                dataloaders,\n",
        "                testloaders , \n",
        "                lernRate=0.01,\n",
        "                all_tranning_loss=[], all_validation_loss=[], all_tranning_accuracy=[], all_validation_accuracy=[]):\n",
        "    since = time.time()\n",
        "    num_epochs = end\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    phase = 'train'\n",
        "    steps = 0\n",
        "\n",
        "    for epoch in range(start,num_epochs):\n",
        "          model.train()\n",
        "          phase = 'tranning'\n",
        "          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "          print('-' * 10)\n",
        "          running_loss = 0.0\n",
        "          running_corrects = 0\n",
        "\n",
        "          for i,(inputs, labels) in enumerate(dataloaders):\n",
        "                \n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                \n",
        "                running_loss += loss.item()\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "\n",
        "                print_val = f\"Epoch: {epoch}/{num_epochs-1} Steps {steps} \\t\"\n",
        "                print_val += f\"running_loss : {(loss.item()):.6f}\\t\"\n",
        "                print_val += f\"running_corrects : {torch.sum(preds == labels.data)}\\t\"  \n",
        "                print_val += f\"total_corrects : {running_corrects}\\t\"  \n",
        "                sys.stdout.write('\\r' + str(print_val))\n",
        "                steps += 1\n",
        "          \n",
        "          \n",
        "          steps = 0\n",
        "          epoch_loss = running_loss / len(dataloaders)\n",
        "          epoch_acc = running_corrects.double().item() /len(dataloaders.dataset)\n",
        "          all_tranning_loss.append(loss.item())\n",
        "          all_tranning_accuracy.append(epoch_acc)\n",
        "          \n",
        "          \n",
        "          print(\"\\n\")\n",
        "          print(\"----------------------------Tranning Summary----------------------\")\n",
        "          print('{} Tranning Avg. Loss: {:.4f} Tranning Avg. Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "          print(\"-\"*70)\n",
        "          print(\"\\n\")\n",
        "\n",
        "          print(\"Start Validation\")\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "              phase = \"validation\"\n",
        "              running_loss = 0.0\n",
        "              running_corrects = 0\n",
        "              for i,(inputs, labels) in enumerate(testloaders):\n",
        "                  inputs, labels = inputs.to(device), labels.to(device)\n",
        "                  outputs = model(inputs)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = criterion(outputs, labels)\n",
        "                    \n",
        "                  running_loss += loss.item()\n",
        "                  running_corrects += torch.sum(preds == labels.data)  \n",
        "\n",
        "                  print_val = f\"Steps {i} \\t\"\n",
        "                  print_val += f\"validation_running_loss : {(loss.item()):.6f}\\t\"\n",
        "                  print_val += f\"validation_running_corrects : {torch.sum(preds == labels.data)}\\t\"  \n",
        "                  print_val += f\"validation_total_corrects : {running_corrects}\\t\"  \n",
        "                  sys.stdout.write('\\r' + str(print_val))\n",
        "\n",
        "              epoch_val_loss = running_loss / len(testloaders)\n",
        "              epoch_val_acc = running_corrects.double().item() /len(testloaders.dataset)\n",
        "              all_validation_loss.append(epoch_val_loss)\n",
        "              all_validation_accuracy.append(epoch_val_acc)\n",
        "\n",
        "              print()\n",
        "              print(\"----------------------------Validation Summary-----------------\")\n",
        "              print('{} Validation Avg. Loss: {:.4f} Validation Avg. Acc: {:.4f}'.format(\n",
        "                    phase, epoch_val_loss, epoch_val_acc))\n",
        "              print(\"------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "          model.train()\n",
        "          \n",
        "          print(\"-------Start Model Save----\\n\\n\")\n",
        "          save_model(model_used,\n",
        "                     model_save_path,\n",
        "                     epoch, \n",
        "                     len(dataloaders),\n",
        "                     model,\n",
        "                     optimizer,\n",
        "                     IMAGE_SIZE,\n",
        "                     tranning_loss=all_tranning_loss,\n",
        "                     tranning_acc= all_tranning_accuracy,\n",
        "                     validation_loss=all_validation_loss,\n",
        "                     validation_acc=all_validation_accuracy,\n",
        "                     learning_rate=lernRate)\n",
        "   \n",
        "      \n",
        "    print(\"Complete Train\")\n",
        "\n",
        "\n",
        "    print()\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6FsRFyEHqXy"
      },
      "source": [
        "!mkdir './Model_2/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMnZf8BkH6pH"
      },
      "source": [
        "START=0\n",
        "END=300\n",
        "model_save_path = './Model_2/' \n",
        "model_used= 'EXPERIMENT_2_MODEL_2'\n",
        "model_ft = model_2\n",
        "\n",
        "\n",
        "optimizer_ft = optimizer\n",
        "trainloader= trainloader\n",
        "testloader = validationloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN8UShC9H8L5"
      },
      "source": [
        "train_model(START, END,model_used, model_save_path, model_ft, criterion, optimizer_ft, trainloader, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SshhudWI6tR"
      },
      "source": [
        "!wget 'https://www.kaggleusercontent.com/kf/74001471/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eK9Z51O5blp1x3n91U0GdA.6uHRztoipwSGYYKJV2B66rGf5rblTIsEazbvhKWGApNX5m6Imr_r5WsuYGwOtRhHeUwz-8IVw7aC8JVKnhSSPZoPM_J8895VyETZWaprmOvHxEQd4AW0JViCxq2Zh_yVShvPgYq1sn4HW6JQa1acUTAaR9DtL_YRa3DBSzSq6nJy_MvN7uFNl7d-q4lEtEDyT6ykDtwa0YsEU9WTFts2o14sk65Sqeav72GtyZqTQ9oUCHR4XWIXIVRTp_UCmLzcTuYm3kudHe3l1KO7QlcsMIBdI0_aBAifXE86jfdCLxNz_D8vecyBIcWLOdRAYfjAclWJvoVZy9T2heBZuENcKf1RBDqzFAHsbS6mHXNFQDcuCpRFFsVTHuw73OBl6ZZ68hidN4wmE9mNvlzaP2k110Zp0nqWdTDUpPnAfT0qnCb_EHajlYF5Xt8QuR_tDz7CEMIDvNW_LGGDwCYhcMwdfXjgO6hjr3apeFcf7ASrUHBJBE5zw0Deu1JQsyzhHulozoWJJe4LVhxEHFVHM_sMNE7NMNyNCY040JILcXQi5iW8b9AqObVOB-BIPajSEHJVxYngbWQNr6-TNlv8uZktdiU78xYvXXwuMk8ic_xdZoITfgNlSx2cQl4wwmOmEqnLxB9xwPCPtR7R2QFJIGaCcA4RXF1Fpd1LEGWUNpW21kk.z4hUXhwzDWEEHI11TEtooA/Model_2.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap19io3YI9aD"
      },
      "source": [
        "!cp '/content/Model_2.zip' '/content/drive/MyDrive/SC_Assignment2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XYXXoFFI_Fu"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/SC_Assignment2/Model_2.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGt1pj7DJDA2"
      },
      "source": [
        "import glob,sys,os\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import torch.optim as optim\n",
        "import time,sys\n",
        "import copy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TCLR0-tJE07"
      },
      "source": [
        "MODEL_LOAD_PATH = '/content/Model_2/EXPERIMENT_2_MODEL_2-checkpoint-epoch-299.pt'\n",
        "model = torch.load(MODEL_LOAD_PATH,map_location='cpu')\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi5p6pU8JHRn"
      },
      "source": [
        "_tranning_loss = model['tranning_loss']\n",
        "_tranning_acc = model['tranning_acc']\n",
        "_validation_loss = model['validation_loss']\n",
        "_validation_acc = model['validation_acc']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE4z_WVoJI_h"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"LOSS Experiment_2_Mydataset\")\n",
        "plt.plot(_tranning_loss,label=\"Tranning Loss\")\n",
        "plt.plot(_validation_loss,label=\"Validation Loss\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYZ7poujJKtj"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Accuracy Experiment_2_Mydataset\")\n",
        "plt.plot(_tranning_acc,label=\"Tranning Accuracy\")\n",
        "plt.plot(_validation_acc,label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}